{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWos8zbZyLxKpIK1kxdHyi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CoShelby/kkkkkk/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmF3Wr8Hu-UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70964c00"
      },
      "source": [
        "# Task\n",
        "Web scrape the content from \"https://hy.wikipedia.org/\" and save the results to a text file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6aa8a16"
      },
      "source": [
        "## Install necessary libraries\n",
        "\n",
        "### Subtask:\n",
        "Install libraries required for web scraping and file handling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6609379e"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries for web scraping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "647283ba",
        "outputId": "9ecbd160-2201-4232-8fd7-2001d8ce9cd7"
      },
      "source": [
        "%pip install requests beautifulsoup4"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81b90d41"
      },
      "source": [
        "## Fetch the webpage content\n",
        "\n",
        "### Subtask:\n",
        "Use a library to fetch the content of the specified URL.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7704bf5"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the requests library, define the URL, fetch the content, store the response, and check the status code as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71396481",
        "outputId": "a284e33f-476e-45b2-ec61-5f4cc5104461"
      },
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://hy.wikipedia.org/\"\n",
        "response = requests.get(url)\n",
        "\n",
        "print(f\"Status Code: {response.status_code}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8922309a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt resulted in a 403 Forbidden error, likely due to the website blocking standard requests. Adding a User-Agent header might help bypass this restriction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c64b60e0",
        "outputId": "9b77295d-608d-472c-f0f0-d539642c7a42"
      },
      "source": [
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
        "}\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "print(f\"Status Code: {response.status_code}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status Code: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53e819d6"
      },
      "source": [
        "## Extract relevant information\n",
        "\n",
        "### Subtask:\n",
        "Parse the webpage content to extract the desired text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b53b9fc"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the `BeautifulSoup` class, create a BeautifulSoup object, and extract the text content from the parsed HTML.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fd575e7",
        "outputId": "1fc709fb-7cd1-47d8-ceaf-947e7a236b7f"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "text_content = soup.get_text()\n",
        "\n",
        "print(text_content[:500])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "Վիքիպեդիա՝ ազատ հանրագիտարան\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jump to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Հիմնական ընտրացանկ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Հիմնական ընտրացանկ\n",
            "տեղափոխել կողագոտի\n",
            "թաքցնել\n",
            "\n",
            "\n",
            "\n",
            "\t\tՆավարկում\n",
            "\t\n",
            "\n",
            "\n",
            "Գլխավոր էջԿատեգորիաներՊատահական հոդվածՆոր էջերԸնթացիկ իրադարձություններ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tՄասնակցել\n",
            "\t\n",
            "\n",
            "\n",
            "ԷությունըԽորհրդարանՎերջին փոփոխություններՕգնությունՍպասարկող էջեր\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Որոնել\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Որոնել\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Արտաքին տեսք\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Նվիրաբերել\n",
            "\n",
            "Ստեղծել հաշիվ\n",
            "\n",
            "Մտնել\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Անձնական գործիքներ\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Նվիրաբ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "702c2e40"
      },
      "source": [
        "## Save the extracted text to a file\n",
        "\n",
        "### Subtask:\n",
        "Write the extracted text into a text file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c5f7d28"
      },
      "source": [
        "**Reasoning**:\n",
        "Write the extracted text to a file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4ffb7b2"
      },
      "source": [
        "with open('hy_wikipedia_content.txt', 'w', encoding='utf-8') as f:\n",
        "  f.write(text_content)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de7ee227"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The initial attempt to fetch the webpage content resulted in a 403 Forbidden error, which was resolved by adding a `User-Agent` header to the request, leading to a successful response with a status code of 200.\n",
        "*   The `BeautifulSoup` library successfully parsed the fetched HTML content and extracted the text using the `get_text()` method.\n",
        "*   The extracted text content was successfully written to a file named `hy_wikipedia_content.txt` using UTF-8 encoding.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The process successfully scraped and saved the text content of the Armenian Wikipedia homepage.\n",
        "*   Further analysis could involve cleaning the extracted text (e.g., removing excess whitespace, headers, footers) to isolate the main article content.\n"
      ]
    }
  ]
}